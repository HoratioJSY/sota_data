{
    "Language Modeling with Gated Convolutional Networks": [
        "method: Gated Convolutional Networks",
        "task: Language Modeling",
        "task recommendation: Language Modeling 0.058823529411764705"
    ],
    "A large annotated corpus for learning natural language inference": [
        "method: large annotated corpus",
        "task: learning natural language inference",
        "task recommendation: Natural Language Inference 0.46153846153846156"
    ],
    "Higher-Order Coreference Resolution with Coarse-to-Fine Inference": [
        "method: Coarse-to-Fine Inference",
        "task: Higher-Order Coreference Resolution",
        "task recommendation: Coreference Resolution 0.6818181818181818"
    ],
    "Deep Fusion LSTMs for Text Semantic Matching": [
        "method: Deep Fusion LSTMs",
        "task: Text Semantic Matching",
        "task recommendation: Semantic Parsing 0.625"
    ],
    "Character-Level Language Modeling with Deeper Self-Attention": [
        "method: Deeper Self-Attention",
        "task: Character-Level Language Modeling",
        "task recommendation: None"
    ],
    "Multiway Attention Networks for Modeling Sentence Pairs": [
        "method: Multiway Attention Networks",
        "task: Modeling Sentence Pairs",
        "task recommendation: None"
    ],
    "DiSAN: Directional Self-Attention Network for RNN/CNN-Free Language Understanding": [
        "method:  Directional Self-Attention Network",
        "task: RNN/CNN-Free Language Understanding",
        "task recommendation: None"
    ],
    "Neural Tree Indexers for Text Understanding": [
        "method: Neural Tree Indexers",
        "task: Text Understanding",
        "task recommendation: Text Generation 0.6"
    ],
    "Learning Natural Language Inference with LSTM": [
        "method: LSTM",
        "task: Learning Natural Language Inference",
        "task recommendation: Natural Language Inference 0.46153846153846156"
    ],
    "Shortcut-Stacked Sentence Encoders for Multi-Domain Inference": [
        "method: Shortcut-Stacked Sentence Encoders",
        "task: Multi-Domain Inference",
        "task recommendation: Multi-Human Parsing 0.5789473684210527"
    ],
    "DR-BiLSTM: Dependent Reading Bidirectional LSTM for Natural Language Inference": [
        "method:  Dependent Reading Bidirectional LSTM",
        "task: Natural Language Inference",
        "task recommendation: Natural Language Inference 0.07692307692307693"
    ],
    "Dynamic Meta-Embeddings for Improved Sentence Representations": [
        "method: Dynamic Meta-Embeddings",
        "task: Improved Sentence Representations",
        "task recommendation: Document Representation 0.6521739130434783"
    ],
    "Enhancing Sentence Embedding with Generalized Pooling": [
        "method: Generalized Pooling",
        "task: Enhancing Sentence Embedding",
        "task recommendation: None"
    ],
    "Enhanced LSTM for Natural Language Inference": [
        "method: Enhanced LSTM",
        "task: Natural Language Inference",
        "task recommendation: Natural Language Inference 0.07692307692307693"
    ],
    "Attribute-Aware Attention Model for Fine-grained Representation Learning": [
        "method: Attribute-Aware Attention Model",
        "task: Fine-grained Representation Learning",
        "task recommendation: Graph Representation Learning 0.41379310344827586"
    ],
    "Attention-based Ensemble for Deep Metric Learning": [
        "method: Attention-based Ensemble",
        "task: Deep Metric Learning",
        "task recommendation: Metric Learning 0.4666666666666667"
    ],
    "Aggregate channel features for multi-view face detection": [
        "method: Aggregate channel features",
        "task: multi-view face detection",
        "task recommendation: Occluded Face Detection 0.4782608695652174"
    ],
    "Striving for Simplicity: The All Convolutional Net": [
        "method: Striving",
        "task: Simplicity",
        "task recommendation: None"
    ],
    "Adaptive Input Representations for Neural Language Modeling": [
        "method: Adaptive Input Representations",
        "task: Neural Language Modeling",
        "task recommendation: Language Modeling 0.5294117647058824"
    ],
    "Iterative Alternating Neural Attention for Machine Reading": [
        "method: Iterative Alternating Neural Attention",
        "task: Machine Reading",
        "task recommendation: Metric Learning 0.5333333333333333"
    ],
    "An All-In-One Convolutional Neural Network for Face Analysis": [
        "method: An All-In-One Convolutional Neural Network",
        "task: Face Analysis",
        "task recommendation: Face Analysis 0.07692307692307693"
    ],
    "A Question-Focused Multi-Factor Attention Network for Question Answering": [
        "method: Question-Focused Multi-Factor Attention Network",
        "task: Question Answering",
        "task recommendation: Question Answering 0.05555555555555555"
    ],
    "Regularized Evolution for Image Classifier Architecture Search": [
        "method: Regularized Evolution",
        "task: Image Classifier Architecture Search",
        "task recommendation: Neural Architecture Search 0.6153846153846154"
    ],
    "Analogical Inference for Multi-Relational Embeddings": [
        "method: Analogical Inference",
        "task: Multi-Relational Embeddings",
        "task recommendation: Multi-Human Parsing 0.7894736842105263"
    ],
    "aNMM: Ranking Short Answer Texts with Attention-Based Neural Matching Model": [
        "method: Attention-Based Neural Matching Model",
        "task:  Ranking Short Answer Texts",
        "task recommendation: None"
    ],
    "Attention-over-Attention Neural Networks for Reading Comprehension": [
        "method: Attention-over-Attention Neural Networks",
        "task: Reading Comprehension",
        "task recommendation: Reading Comprehension 0.047619047619047616"
    ],
    "APAC: Augmented PAttern Classification with Neural Networks": [
        "method: Neural Networks",
        "task:  Augmented PAttern Classification",
        "task recommendation: Document Image Classification 0.4482758620689655"
    ],
    "Training with Exploration Improves a Greedy Stack-LSTM Parser": [
        "method: Exploration Improves",
        "task: Training",
        "task recommendation: Reasoning 0.4444444444444444"
    ],
    "Convolutional Neural Network Architectures for Matching Natural Language Sentences": [
        "method: Convolutional Neural Network Architectures",
        "task: Matching Natural Language Sentences",
        "task recommendation: Natural Language Inference 0.6538461538461539"
    ],
    "ArcFace: Additive Angular Margin Loss for Deep Face Recognition": [
        "method:  Additive Angular Margin Loss",
        "task: Deep Face Recognition",
        "task recommendation: Face Recognition 0.4375"
    ],
    "Asymmetric Tri-training for Unsupervised Domain Adaptation": [
        "method: Asymmetric Tri-training",
        "task: Unsupervised Domain Adaptation",
        "task recommendation: Unsupervised Domain Adaptation 0.06666666666666667"
    ],
    "Edinburgh Neural Machine Translation SystEMs for WMT 16": [
        "method: Edinburgh Neural Machine Translation SystEMs",
        "task: WMT 16",
        "task recommendation: None"
    ],
    "Neural Variational Inference for Text Processing": [
        "method: Neural Variational Inference",
        "task: Text Processing",
        "task recommendation: Text Compression 0.4375"
    ],
    "AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks": [
        "method: Attentional Generative Adversarial Networks",
        "task:  Fine-Grained Text to Image Generation",
        "task recommendation: Fine-Grained Image Classification 0.6060606060606061"
    ],
    "Direct Output Connection for a High-Rank Language Model": [
        "method: Direct Output Connection",
        "task: ",
        "task recommendation: None"
    ],
    "A Large Self-Annotated Corpus for Sarcasm": [
        "method: Large Self-Annotated Corpus",
        "task: Sarcasm",
        "task recommendation: Amr Parsing 0.7272727272727273"
    ],
    "Passage Re-ranking with BERT": [
        "method: BERT",
        "task: Passage Re-ranking",
        "task recommendation: Passage Re-Ranking 0.1111111111111111"
    ],
    "A BERT Baseline for the Natural Questions": [
        "method: BERT Baseline",
        "task: the Natural Questions",
        "task recommendation: Pedestrian Detection 0.65"
    ],
    "Leveraging Multi-grained Sentiment Lexicon Information for Neural Sequence Models": [
        "method: Leveraging Multi-grained Sentiment Lexicon Information",
        "task: Neural Sequence Models",
        "task recommendation: Sequence Modeling 0.7058823529411765"
    ],
    "SEMi-supervised Multitask Learning for Sequence Labeling": [
        "method: SEMi-supervised Multitask Learning",
        "task: Sequence Labeling",
        "task recommendation: Sequence Modeling 0.17647058823529413"
    ],
    "Speech Recognition with Deep Recurrent Neural Networks": [
        "method: Deep Recurrent Neural Networks",
        "task: Speech Recognition",
        "task recommendation: Speech Recognition 0.05555555555555555"
    ],
    "Robust Lexical Features for Improved Neural Network Named-Entity Recognition": [
        "method: Robust Lexical Features",
        "task: Improved Neural Network Named-Entity Recognition",
        "task recommendation: None"
    ],
    "Neural Sequence Learning Models for Word Sense Disambiguation": [
        "method: Neural Sequence Learning Models",
        "task: Word Sense Disambiguation",
        "task recommendation: Word Sense Disambiguation 0.08"
    ],
    "Attention-Based Models for Speech Recognition": [
        "method: Attention-Based Models",
        "task: Speech Recognition",
        "task recommendation: Speech Recognition 0.05555555555555555"
    ],
    "Multi-range Reasoning for Machine Comprehension": [
        "method: Multi-range Reasoning",
        "task: Machine Comprehension",
        "task recommendation: Reading Comprehension 0.2857142857142857"
    ],
    "Bidirectional Attention Flow for Machine Comprehension": [
        "method: Bidirectional Attention Flow",
        "task: Machine Comprehension",
        "task recommendation: Reading Comprehension 0.2857142857142857"
    ],
    "Factorization tricks for LSTM networks": [
        "method: Factorization tricks",
        "task: LSTM networks",
        "task recommendation: Lane Detection 0.7142857142857143"
    ],
    "Large Scale GAN Training for High Fidelity Natural Image Synthesis": [
        "method: Large Scale GAN Training",
        "task: High Fidelity Natural Image Synthesis",
        "task recommendation: None"
    ],
    "Deep Learning for Answer Sentence Selection": [
        "method: Deep Learning",
        "task: Answer Sentence Selection",
        "task recommendation: Answer Selection 0.625"
    ],
    "Edinburgh Neural Machine Translation Systems for WMT 16": [
        "method: Edinburgh Neural Machine Translation Systems",
        "task: WMT 16",
        "task recommendation: None"
    ],
    "A Convolutional Encoder Model for Neural Machine Translation": [
        "method: Convolutional Encoder Model",
        "task: Neural Machine Translation",
        "task recommendation: Neural Machine Translation 0.07692307692307693"
    ],
    "Can Syntax Help? Improving an LSTM-based Sentence Compression Model for New Domains": [
        "method: LSTM-based Sentence Compression Model",
        "task: New Domains",
        "task recommendation: Reasoning 0.7777777777777778"
    ],
    "A Span Selection Model for Semantic Role Labeling": [
        "method: Span Selection Model",
        "task: Semantic Role Labeling",
        "task recommendation: Semantic Role Labeling 0.09090909090909091"
    ],
    "Bilateral Multi-Perspective Matching for Natural Language Sentences": [
        "method: Bilateral Multi-Perspective Matching",
        "task: Natural Language Sentences",
        "task recommendation: Natural Language Inference 0.2692307692307692"
    ],
    "A Language Model based Evaluator for Sentence Compression": [
        "method: Language Model based Evaluator",
        "task: Sentence Compression",
        "task recommendation: Text Compression 0.4375"
    ],
    "BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation": [
        "method:  Bilateral Segmentation Network",
        "task: Real-time Semantic Segmentation",
        "task recommendation: Real-time Semantic Segmentation 0.06451612903225806"
    ],
    "GPU Kernels for Block-Sparse Weights": [
        "method: GPU Kernels",
        "task: Block-Sparse Weights",
        "task recommendation: Multi-Armed Bandits 0.7894736842105263"
    ],
    "BoxSup: Exploiting Bounding Boxes to Supervise Convolutional Networks for Semantic Segmentation": [
        "method:  Exploiting Bounding Boxes to Supervise Convolutional Networks",
        "task: Semantic Segmentation",
        "task recommendation: Semantic Segmentation 0.047619047619047616"
    ],
    "Bidirectional Recurrent Convolutional Networks for Multi-Frame Super-Resolution": [
        "method: Bidirectional Recurrent Convolutional Networks",
        "task: Multi-Frame Super-Resolution",
        "task recommendation: Image Super-Resolution 0.5"
    ],
    "A C-LSTM Neural Network for Text Classification": [
        "method: C-LSTM Neural Network",
        "task: Text Classification",
        "task recommendation: Text Classification 0.05263157894736842"
    ],
    "Unsupervised Feature Learning with C-SVDDNet": [
        "method: C-SVDDNet",
        "task: Unsupervised Feature Learning",
        "task recommendation: Representation Learning 0.6521739130434783"
    ],
    "Semi-Supervised Learning with Context-Conditional Generative Adversarial Networks": [
        "method: Context-Conditional Generative Adversarial Networks",
        "task: Semi-Supervised Learning",
        "task recommendation: Semi-Supervised Learning 0.08333333333333333"
    ],
    "CenterNet: Keypoint Triplets for Object Detection": [
        "method:  Keypoint Triplets",
        "task: Object Detection",
        "task recommendation: Object Detection 0.0625"
    ],
    "Coarse-grain Fine-grain Coattention Network for Multi-evidence Question Answering": [
        "method: Coarse-grain Fine-grain Coattention Network",
        "task: Multi-evidence Question Answering",
        "task recommendation: Memex Question Answering 0.5416666666666666"
    ],
    "Image-to-Image Translation with Conditional Adversarial Networks": [
        "method: Conditional Adversarial Networks",
        "task: Image-to-Image Translation",
        "task recommendation: Image-To-Image Translation 0.11538461538461539"
    ],
    "Global Encoding for Abstractive Summarization": [
        "method: Global Encoding",
        "task: Abstractive Summarization",
        "task recommendation: Abstractive Summarization 0.04"
    ],
    "Character-level Convolutional Networks for Text Classification": [
        "method: Character-level Convolutional Networks",
        "task: Text Classification",
        "task recommendation: Text Classification 0.05263157894736842"
    ],
    "A Simple Method for Commonsense Reasoning": [
        "method: Simple Method",
        "task: Commonsense Reasoning",
        "task recommendation: Common Sense Reasoning 0.13636363636363635"
    ],
    "SEMi-Supervised Sequence Modeling with Cross-View Training": [
        "method: Cross-View Training",
        "task: SEMi-Supervised Sequence Modeling",
        "task recommendation: Semi-Supervised Learning 0.5416666666666666"
    ],
    "CMS-RCNN: Contextual Multi-Scale Region-based CNN for Unconstrained Face Detection": [
        "method:  Contextual Multi-Scale Region-based CNN",
        "task: Unconstrained Face Detection",
        "task recommendation: Occluded Face Detection 0.5217391304347826"
    ],
    "A Multilayer Convolutional Encoder-Decoder Neural Network for Grammatical Error Correction": [
        "method: Multilayer Convolutional Encoder-Decoder Neural Network",
        "task: Grammatical Error Correction",
        "task recommendation: Grammatical Error Correction 0.07142857142857142"
    ],
    "Convolutional Neural Networks with Recurrent Neural Filters": [
        "method: Recurrent Neural Filters",
        "task: Convolutional Neural Networks",
        "task recommendation: Conditional Program Generation 0.5666666666666667"
    ],
    "Improved Variational Autoencoders for Text Modeling using Dilated Convolutions": [
        "method: Improved Variational Autoencoders",
        "task: Text Modeling",
        "task recommendation: Music Modeling 0.42857142857142855"
    ],
    "Complex Embeddings for Simple Link Prediction": [
        "method: Complex Embeddings",
        "task: Simple Link Prediction",
        "task recommendation: Link Prediction 0.6"
    ],
    "Canonical Tensor Decomposition for Knowledge Base Completion": [
        "method: Canonical Tensor Decomposition",
        "task: Knowledge Base Completion",
        "task recommendation: Knowledge Graph Completion 0.19230769230769232"
    ],
    "Context Based Approach for Second Language Acquisition": [
        "method: Context Based Approach",
        "task: Second Language Acquisition",
        "task recommendation: Language Acquisition 0.45"
    ],
    "Convolutional Clustering for Unsupervised Learning": [
        "method: Convolutional Clustering",
        "task: Unsupervised Learning",
        "task recommendation: Semi-Supervised Learning 0.2916666666666667"
    ],
    "Classical Structured Prediction Losses for Sequence to Sequence Learning": [
        "method: Classical Structured Prediction Losses",
        "task: Sequence to Sequence Learning",
        "task recommendation: None"
    ],
    "Cut to the Chase: A Context Zoom-in Network for Reading Comprehension": [
        "method: Context Zoom-in Network",
        "task: Reading Comprehension",
        "task recommendation: Reading Comprehension 0.047619047619047616"
    ],
    "Neural Models for Reasoning over Multiple Mentions using Coreference": [
        "method: Neural Models",
        "task: Reasoning over Multiple Mentions",
        "task recommendation: None"
    ],
    "CosFace: Large Margin Cosine Loss for Deep Face Recognition": [
        "method:  Large Margin Cosine Loss",
        "task: Deep Face Recognition",
        "task recommendation: Face Recognition 0.4375"
    ],
    "Photographic Image Synthesis with Cascaded Refinement Networks": [
        "method: Cascaded Refinement Networks",
        "task: Photographic Image Synthesis",
        "task recommendation: Program Synthesis 0.7647058823529411"
    ],
    "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation": [
        "method: RNN Encoder-Decoder",
        "task: Statistical Machine Translation",
        "task recommendation: Neural Machine Translation 0.4230769230769231"
    ],
    "Improving End-to-End Speech Recognition with Policy Learning": [
        "method: Policy Learning",
        "task: Improving End-to-End Speech Recognition",
        "task recommendation: Accented Speech Recognition 0.6296296296296297"
    ],
    "A Helping Hand: Transfer Learning for Deep Sentiment Analysis": [
        "method:  Transfer Learning",
        "task: Deep Sentiment Analysis",
        "task recommendation: Sentiment Analysis 0.3888888888888889"
    ],
    "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks": [
        "method: Deep Convolutional Generative Adversarial Networks",
        "task: Unsupervised Representation Learning",
        "task recommendation: Graph Representation Learning 0.4482758620689655"
    ],
    "Densely Connected Attention Propagation for Reading Comprehension": [
        "method: Densely Connected Attention Propagation",
        "task: Reading Comprehension",
        "task recommendation: Reading Comprehension 0.047619047619047616"
    ],
    "Deep Biaffine Attention for Neural Dependency Parsing": [
        "method: Deep Biaffine Attention",
        "task: Neural Dependency Parsing",
        "task recommendation: Dependency Parsing 0.5"
    ],
    "A Deep Cascade Model for Multi-Document Reading Comprehension": [
        "method: Deep Cascade Model",
        "task: Multi-Document Reading Comprehension",
        "task recommendation: Machine Reading Comprehension 0.4482758620689655"
    ],
    "Very Deep Multilingual Convolutional Neural Networks for LVCSR": [
        "method: Very Deep Multilingual Convolutional Neural Networks",
        "task: LVCSR",
        "task recommendation: None"
    ],
    "Learning Deep CNN Denoiser Prior for Image Restoration": [
        "method: Learning Deep CNN Denoiser Prior",
        "task: Image Restoration",
        "task recommendation: Image Generation 0.25"
    ],
    "Deep Joint Entity Disambiguation with Local Neural Attention": [
        "method: Local Neural Attention",
        "task: Deep Joint Entity Disambiguation",
        "task recommendation: Word Sense Disambiguation 0.6"
    ],
    "Deep Mean-Shift Priors for Image Restoration": [
        "method: Deep Mean-Shift Priors",
        "task: Image Restoration",
        "task recommendation: Image Generation 0.25"
    ],
    "DeepFM: A Factorization-Machine based Neural Network for CTR Prediction": [
        "method: Factorization-Machine based Neural Network",
        "task: CTR Prediction",
        "task recommendation: CTR Prediction 0.21428571428571427"
    ],
    "Rethinking Atrous Convolution for Semantic Image Segmentation": [
        "method: Rethinking Atrous Convolution",
        "task: Semantic Image Segmentation",
        "task recommendation: Semantic Segmentation 0.3333333333333333"
    ],
    "Large-Scale Image Retrieval with Attentive Deep Local Features": [
        "method: Attentive Deep Local Features",
        "task: Large-Scale Image Retrieval",
        "task recommendation: None"
    ],
    "DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling": [
        "method: Directed Sparse Sampling",
        "task:  Scalable Real-time Object Detection",
        "task recommendation: Weakly Supervised Object Detection 0.5"
    ],
    "Dense 3D Regression for Hand Pose Estimation": [
        "method: Dense 3D Regression",
        "task: Hand Pose Estimation",
        "task recommendation: Hand Pose Estimation 0.1"
    ],
    "DeXpression: Deep Convolutional Neural Network for Expression Recognition": [
        "method:  Deep Convolutional Neural Network",
        "task: Expression Recognition",
        "task recommendation: Action Recognition 0.4444444444444444"
    ],
    "Deeply-Learned Part-Aligned Representations for Person Re-Identification": [
        "method: Deeply-Learned Part-Aligned Representations",
        "task: Person Re-Identification",
        "task recommendation: Person Re-Identification 0.08333333333333333"
    ],
    "Efficient Yet Deep Convolutional Neural Networks for Semantic Segmentation": [
        "method: Efficient Yet Deep Convolutional Neural Networks",
        "task: Semantic Segmentation",
        "task recommendation: Semantic Segmentation 0.047619047619047616"
    ],
    "Deep Interest Network for Click-Through Rate Prediction": [
        "method: Deep Interest Network",
        "task: Click-Through Rate Prediction",
        "task recommendation: Click-Through Rate Prediction 0.10344827586206896"
    ],
    "Deep Image Retrieval: Learning global representations for image search": [
        "method:  Learning global representations",
        "task: image search",
        "task recommendation: Image Retrieval 0.4666666666666667"
    ],
    "Discriminative Unsupervised Feature Learning with Convolutional Neural Networks": [
        "method: Convolutional Neural Networks",
        "task: Discriminative Unsupervised Feature Learning",
        "task recommendation: None"
    ],
    "Distance-based Self-Attention Network for Natural Language Inference": [
        "method: Distance-based Self-Attention Network",
        "task: Natural Language Inference",
        "task recommendation: Natural Language Inference 0.07692307692307693"
    ],
    "A Discriminatively Learned CNN Embedding for Person Re-identification": [
        "method: Discriminatively Learned CNN Embedding",
        "task: Person Re-identification",
        "task recommendation: Person Re-Identification 0.08333333333333333"
    ],
    "Building DNN Acoustic Models for Large Vocabulary Speech Recognition": [
        "method: Building DNN Acoustic Models",
        "task: Large Vocabulary Speech Recognition",
        "task recommendation: Noisy Speech Recognition 0.6666666666666666"
    ],
    "Learning a Discriminative Null Space for Person Re-identification": [
        "method: Discriminative Null Space",
        "task: Person Re-identification",
        "task recommendation: Person Re-Identification 0.08333333333333333"
    ],
    "Deep Pyramid Convolutional Neural Networks for Text Categorization": [
        "method: Deep Pyramid Convolutional Neural Networks",
        "task: Text Categorization",
        "task recommendation: Text Summarization 0.3333333333333333"
    ],
    "Deeply-Recursive Convolutional Network for Image Super-Resolution": [
        "method: Deeply-Recursive Convolutional Network",
        "task: Image Super-Resolution",
        "task recommendation: Image Super-Resolution 0.09090909090909091"
    ],
    "Deep Recurrent Generative Decoder for Abstractive Text Summarization": [
        "method: Deep Recurrent Generative Decoder",
        "task: Abstractive Text Summarization",
        "task recommendation: Abstractive Summarization 0.24"
    ],
    "A Deep Relevance Matching Model for Ad-hoc Retrieval": [
        "method: Deep Relevance Matching Model",
        "task: Ad-hoc Retrieval",
        "task recommendation: Person Retrieval 0.375"
    ],
    "Disconnected Recurrent Neural Networks for Text Categorization": [
        "method: Disconnected Recurrent Neural Networks",
        "task: Text Categorization",
        "task recommendation: Text Summarization 0.3333333333333333"
    ],
    "Quantized Densely Connected U-Nets for Efficient Landmark Localization": [
        "method: Quantized Densely Connected U-Nets",
        "task: Efficient Landmark Localization",
        "task recommendation: Facial Landmark Detection 0.64"
    ],
    "Dual Attention Network for Scene Segmentation": [
        "method: Dual Attention Network",
        "task: Scene Segmentation",
        "task recommendation: Scene Segmentation 0.05555555555555555"
    ],
    "DualGAN: Unsupervised Dual Learning for Image-to-Image Translation": [
        "method:  Unsupervised Dual Learning",
        "task: Image-to-Image Translation",
        "task recommendation: Image-To-Image Translation 0.11538461538461539"
    ],
    "An Updated Duet Model for Passage Re-ranking": [
        "method: An Updated Duet Model",
        "task: Passage Re-ranking",
        "task recommendation: Passage Re-Ranking 0.1111111111111111"
    ],
    "Decoders Matter for Semantic Segmentation: Data-Dependent Decoding Enables Flexible Feature Aggregation": [
        "method: Decoders Matter",
        "task: Semantic Segmentation",
        "task recommendation: Semantic Segmentation 0.047619047619047616"
    ],
    "Dynamic Entity Representation with Max-pooling Improves Machine Reading": [
        "method: Max-pooling Improves Machine Reading",
        "task: Dynamic Entity Representation",
        "task recommendation: Document Representation 0.43478260869565216"
    ],
    "Enhanced Deep Residual Networks for Single Image Super-Resolution": [
        "method: Enhanced Deep Residual Networks",
        "task: Single Image Super-Resolution",
        "task recommendation: Video Image Super-Resolution 0.2857142857142857"
    ],
    "Context Encoding for Semantic Segmentation": [
        "method: Context Encoding",
        "task: Semantic Segmentation",
        "task recommendation: Semantic Segmentation 0.047619047619047616"
    ],
    "Tracking the World State with Recurrent Entity Networks": [
        "method: Recurrent Entity Networks",
        "task: World State",
        "task recommendation: None"
    ],
    "Natural Language Comprehension with the EpiReader": [
        "method: the EpiReader",
        "task: Natural Language Comprehension",
        "task recommendation: Natural Language Inference 0.4230769230769231"
    ],
    "SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference": [
        "method: Large-Scale Adversarial Dataset",
        "task: Grounded Commonsense Inference",
        "task recommendation: Commonsense Inference 0.5238095238095238"
    ],
    "FaceBoxes: A CPU Real-time Face Detector with High Accuracy": [
        "method: High Accuracy",
        "task: CPU Real-time Face Detector",
        "task recommendation: None"
    ],
    "Speed/accuracy trade-offs for modern convolutional object detectors": [
        "method: Speed/accuracy trade-offs",
        "task: modern convolutional object detectors",
        "task recommendation: None"
    ],
    "Deep Residual Learning for Image Recognition": [
        "method: Deep Residual Learning",
        "task: Image Recognition",
        "task recommendation: Image Recognition 0.058823529411764705"
    ],
    "Feature Pyramid Networks for Object Detection": [
        "method: Feature Pyramid Networks",
        "task: Object Detection",
        "task recommendation: Object Detection 0.0625"
    ],
    "Beyond Skip Connections: Top-Down Modulation for Object Detection": [
        "method:  Top-Down Modulation",
        "task: Object Detection",
        "task recommendation: Object Detection 0.0625"
    ],
    "The One Hundred Layers Tiramisu: Fully Convolutional DenseNets for Semantic Segmentation": [
        "method:  Fully Convolutional DenseNets",
        "task: Semantic Segmentation",
        "task recommendation: Semantic Segmentation 0.047619047619047616"
    ],
    "Fully Convolutional Networks for Semantic Segmentation": [
        "method: Fully Convolutional Networks",
        "task: Semantic Segmentation",
        "task recommendation: Semantic Segmentation 0.047619047619047616"
    ],
    "A Focused Dynamic Attention Model for Visual Question Answering": [
        "method: Focused Dynamic Attention Model",
        "task: Visual Question Answering",
        "task recommendation: Visual Question Answering 0.08"
    ],
    "Contextual String Embeddings for Sequence Labeling": [
        "method: Contextual String Embeddings",
        "task: Sequence Labeling",
        "task recommendation: Sequence Modeling 0.17647058823529413"
    ],
    "Neural Ranking Models with Weak Supervision": [
        "method: Weak Supervision",
        "task: Neural Ranking Models",
        "task recommendation: None"
    ],
    "FOTS: Fast Oriented Text Spotting with a Unified Network": [
        "method: ",
        "task:  Fast Oriented Text Spotting",
        "task recommendation: None"
    ],
    "FacePoseNet: Making a Case for Landmark-Free Face Alignment": [
        "method: Case",
        "task: Landmark-Free Face Alignment",
        "task recommendation: None"
    ],
    "Feature Selective Anchor-Free Module for Single-Shot Object Detection": [
        "method: Feature Selective Anchor-Free Module",
        "task: Single-Shot Object Detection",
        "task recommendation: One-Shot Object Detection 0.28"
    ],
    "Fused Text Segmentation Networks for Multi-oriented Scene Text Detection": [
        "method: Fused Text Segmentation Networks",
        "task: Multi-oriented Scene Text Detection",
        "task recommendation: None"
    ],
    "Gated-Attention Readers for Text Comprehension": [
        "method: Gated-Attention Readers",
        "task: Text Comprehension",
        "task recommendation: Text Compression 0.25"
    ],
    "Letter-Based Speech Recognition with Gated ConvNets": [
        "method: Gated ConvNets",
        "task: Letter-Based Speech Recognition",
        "task recommendation: Accented Speech Recognition 0.4074074074074074"
    ],
    "Conditional Image Generation with PixelCNN Decoders": [
        "method: PixelCNN Decoders",
        "task: Conditional Image Generation",
        "task recommendation: Conditional Program Generation 0.23333333333333334"
    ],
    "Semi-Supervised Classification with Graph Convolutional Networks": [
        "method: Graph Convolutional Networks",
        "task: Semi-Supervised Classification",
        "task recommendation: Semi-Supervised Image Classification 0.2222222222222222"
    ],
    "GhostVLAD for set-based face recognition": [
        "method: GhostVLAD",
        "task: set-based face recognition",
        "task recommendation: Displaced people recognition 0.39285714285714285"
    ],
    "Git Loss for Deep Face Recognition": [
        "method: Git Loss",
        "task: Deep Face Recognition",
        "task recommendation: Face Recognition 0.4375"
    ],
    "GLAD: Global-Local-Alignment Descriptor for Pedestrian Retrieval": [
        "method:  Global-Local-Alignment Descriptor",
        "task: Pedestrian Retrieval",
        "task recommendation: Pedestrian Detection 0.35"
    ],
    "Glow: Generative Flow with Invertible 1x1 Convolutions": [
        "method: Invertible 1x1 Convolutions",
        "task:  Generative Flow",
        "task recommendation: Text Generation 0.7333333333333333"
    ],
    "Graph-Structured Representations for Visual Question Answering": [
        "method: Graph-Structured Representations",
        "task: Visual Question Answering",
        "task recommendation: Visual Question Answering 0.08"
    ],
    "A Graph-to-Sequence Model for AMR-to-Text Generation": [
        "method: Graph-to-Sequence Model",
        "task: AMR-to-Text Generation",
        "task recommendation: Data-to-Text Generation 0.2608695652173913"
    ],
    "Graph2Seq: Graph to Sequence Learning with Attention-based Neural Networks": [
        "method: Attention-based Neural Networks",
        "task:  Graph to Sequence Learning",
        "task recommendation: None"
    ],
    "Learning Graph-Level Representation for Drug Discovery": [
        "method: Learning Graph-Level Representation",
        "task: Drug Discovery",
        "task recommendation: Drug Discovery 0.07142857142857142"
    ],
    "GraphGAN: Graph Representation Learning with Generative Adversarial Nets": [
        "method: Generative Adversarial Nets",
        "task:  Graph Representation Learning",
        "task recommendation: Graph Representation Learning 0.13793103448275862"
    ],
    "HD-CNN: Hierarchical Deep Convolutional Neural Network for Large Scale Visual Recognition": [
        "method:  Hierarchical Deep Convolutional Neural Network",
        "task: Large Scale Visual Recognition",
        "task recommendation: License Plate Recognition 0.56"
    ],
    "Story Comprehension for Predicting What Happens Next": [
        "method: Story Comprehension",
        "task: Predicting What Happens Next",
        "task recommendation: None"
    ],
    "WaveNet: A Generative Model for Raw Audio": [
        "method: Generative Model",
        "task: Raw Audio",
        "task recommendation: Game of Go 0.7"
    ],
    "Hierarchical Question-Image Co-Attention for Visual Question Answering": [
        "method: Hierarchical Question-Image Co-Attention",
        "task: Visual Question Answering",
        "task recommendation: Visual Question Answering 0.08"
    ],
    "Deep High-Resolution Representation Learning for Human Pose Estimation": [
        "method: Deep High-Resolution Representation Learning",
        "task: Human Pose Estimation",
        "task recommendation: Human Pose Estimation 0.09523809523809523"
    ],
    "Hybrid semi-Markov CRF for Neural Sequence Labeling": [
        "method: Hybrid semi-Markov CRF",
        "task: Neural Sequence Labeling",
        "task recommendation: Sequence Modeling 0.6470588235294118"
    ],
    "HyperDense-Net: A hyper-densely connected CNN for multi-modal image segmentation": [
        "method: hyper-densely connected CNN",
        "task: multi-modal image segmentation",
        "task recommendation: Medical Image Segmentation 0.34615384615384615"
    ],
    "Simple Baseline for Visual Question Answering": [
        "method: Simple Baseline",
        "task: Visual Question Answering",
        "task recommendation: Visual Question Answering 0.08"
    ],
    "Invertible Conditional GANs for image editing": [
        "method: Invertible Conditional GANs",
        "task: image editing",
        "task recommendation: Image Denoising 0.26666666666666666"
    ],
    "Camera Style Adaptation for Person Re-identification": [
        "method: Style Adaptation",
        "task: Person Re-identification",
        "task recommendation: Person Re-Identification 0.08333333333333333"
    ]
}